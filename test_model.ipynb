{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# Any results you write to the current directory are saved as output.\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D, Convolution2D\nfrom keras.optimizers import SGD, Adam, RMSprop\nfrom keras.metrics import categorical_accuracy\nfrom keras import regularizers\nfrom tqdm import tqdm\nfrom PIL import Image\n\nimport numpy as np\nimport pandas as pd\nimport random\nimport tensorflow as tf\nimport cv2\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport os\nprint(os.listdir(\"../input\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    \"\"\"\n    Crop out black borders\n    https://www.kaggle.com/ratthachat/aptos-updated-preprocessing-ben-s-cropping\n    \"\"\"  \n    \n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        mask = gray_img>tol        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0):\n            return img\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n\n\ndef circle_crop(img):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)    \n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    \n    return img \n\ndef circle_crop_v2(img):\n    \"\"\"\n    Create circular crop around image centre\n    \"\"\"\n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)\n\n    height, width, depth = img.shape\n    largest_side = np.max((height, width))\n    img = cv2.resize(img, (largest_side, largest_side))\n\n    height, width, depth = img.shape\n\n    x = int(width / 2)\n    y = int(height / 2)\n    r = np.amin((x, y))\n\n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load all the image names in train images file \nimg_size = 300\nbatch_size=32\n\nfrom keras_preprocessing.image import ImageDataGenerator\ndef append_ext(fn):\n    return fn+\".png\"\n\ndef convert_int(i):\n    return str(i)\n\n#image preprocessing\ndef preprocess_image(image_path):\n    \n    image = cv2.imread(image_path)\n    #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    #ret3,image = cv2.threshold(image, 129, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n    image = cv2.resize(image, (img_size, img_size))\n    image = cv2.addWeighted(image,4, cv2.GaussianBlur(image,(0,0),img_size/10),-4 ,128)\n    plt.imshow(image)\n#    cv2.applyColorMap(im, cv2.COLORMAP_JET)\n    return image\n\ntestdf=pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\ntestdf[\"id_code\"]=testdf[\"id_code\"].apply(append_ext)\ntestdf[\"diagnosis\"]=testdf[\"diagnosis\"].apply(convert_int)\nimage_path = \"color_images_test\"\n#image_path = \"../input/images-test/gray_images_test/gray_images_test\"\nN = testdf.shape[0]\nx_test = np.empty((N, 300, 300, 3), dtype=np.uint8)\nfor i, image_id in enumerate(tqdm(testdf['id_code'])):\n    x_test[i, :, :, :] = preprocess_image(f'../input/aptos2019-blindness-detection/test_images/{image_id}')\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.applications import ResNet50\n# resnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n# resNet50 = ResNet50(include_top = False, pooling = 'avg', weights = resnet_weights_path,classes=5)\n# model = Sequential()\n# model.add(resNet50)\n# model.add(Dense(5, activation='softmax',activity_regularizer=regularizers.l1(0.001)))\n# model.summary()\n# model.load_weights('../input/graymodel/best_aptos_model (2).hdf5')\n\n# from keras.applications import VGG16\n# VGG16_weights_path = '../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n# vgg16 = VGG16(include_top=False,input_shape=(300, 300, 3),weights = VGG16_weights_path,classes=5)\n# model = Sequential()\n# model.add(vgg16)\n# model.add(Flatten())\n# model.add(Dense(256, activation='relu',activity_regularizer=regularizers.l2(0.001)))\n# model.add(Dense(256, activation='relu',activity_regularizer=regularizers.l2(0.001)))\n# model.add(Dropout(0.25))\n# model.add(Dense(5, activation='softmax',activity_regularizer=regularizers.l1(0.001)))\n# model.summary()\n# model.load_weights('../input/colormodel/color_model.hdf5')\n\nfrom keras.applications import InceptionResNetV2\ninceptionResNetV2_path = '../input/inceptionresnetv2/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\ninceptionResNetV2 = InceptionResNetV2(include_top=False,input_shape=(300, 300, 3),weights = inceptionResNetV2_path,classes=5)\n\nmodel = Sequential()\nmodel.add(inceptionResNetV2)\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu',activity_regularizer=regularizers.l2(0.001)))\nmodel.add(Dense(256, activation='relu',activity_regularizer=regularizers.l2(0.001)))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(5, activation='softmax',activity_regularizer=regularizers.l1(0.001)))\nmodel.summary()\n# model.load_weights('../input/inceptionResNetV2/inceptionResNetV2.hdf5')\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"\ntest_datagen=ImageDataGenerator(\n    rescale=1./255.,\n#     horizontal_flip=True,\n# #     fill_mode='nearest',\n#     zca_whitening=True,\n)\ntest_generator = test_datagen.flow(\n    x_test,\n    batch_size=batch_size\n)\n\ntest_generator.reset()\ntest_pred=model.predict_generator(test_generator,steps=len(test_generator),verbose=1)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #TTA\n# tta_steps = 10\n# predictions = []\n\n# for i in tqdm(range(tta_steps)):\n#     preds = model.predict_generator(test_datagen.flow(test_generator, batch_size=batch_size, shuffle=False), steps = len(validation_data)/batch_size)\n#     predictions.append(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_pred = np.mean(test_pred, axis=0)\npredicted_class=np.argmax(test_pred,axis=1)\nprint(predicted_class[:10])\nimport collections\nprint(collections.Counter(predicted_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\nsample.diagnosis = predicted_class.astype(int)\nsample.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}